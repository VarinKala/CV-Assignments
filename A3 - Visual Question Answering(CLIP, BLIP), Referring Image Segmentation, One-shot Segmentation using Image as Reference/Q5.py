# -*- coding: utf-8 -*-
"""CV_A3_5

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/varinkala/cv-a3-5.eb82685a-8d40-4497-a5f1-082779589c4f.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250420/auto/storage/goog4_request%26X-Goog-Date%3D20250420T170651Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D011d3a452c20c3208147a6e6beb98270c30f661985c5f95d17f4edd00e3b2bc54d025dd956e98a3a0bd98b33b90f434402d83de2fd72605f6bd49a2ab97a2c3bfbc503343c4dae14c171f10e3a8284eb65adb5484e34769c81ac84aa56251d3990473022266351fd0392f39fbe7fcaa2a9393f122c16694d77494786a62f665fb09eb2ad6236c9fc9fb77cc24df5f64094352bcf8286b6475c534d15a61dc32f51b762fb33be20933bc46a44f826a72a1093675c66c14ba6bd2b11443a96ff1a1d0926499b569f9090d1ab802f315863396dd404024c3a0db6d9313b25fa0cb9d93f39c070bc9079b70b774aaaaeb88ba468f6859e80e4da422d1cb3d3bb3e3e
"""

!sudo apt-get update -y
!sudo apt-get install python3.9 python3.9-distutils python3.9-dev -y

!wget https://bootstrap.pypa.io/get-pip.py
!python3.9 get-pip.py

# import os
# os.symlink('/usr/bin/python3.9', '/usr/bin/python')
# os.system('python --version')

!python --version

# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE
# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.
import kagglehub
# kagglehub.login()
kagglehub.login({
    "username": "varinkala",
    "key": "fba0c1d00c2aeea2d68a62e6237aea93"
})

# Username: varinkala
# token: fba0c1d00c2aeea2d68a62e6237aea93

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

# varinkala_cv_a3_all_path = kagglehub.dataset_download('varinkala/cv-a3-all')

# print('Data source import complete.')

# print(varinkala_cv_a3_all_path)

# # This Python 3 environment comes with many helpful analytics libraries installed
# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# # For example, here's several helpful packages to load

# import numpy as np # linear algebra
# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# # Input data files are available in the read-only "../input/" directory
# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

# import os
# for dirname, _, filenames in os.walk(varinkala_cv_a3_all_path):
#     for filename in filenames:
#         print(os.path.join(dirname, filename))

# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

# import numpy as np
# import matplotlib.pyplot as plt
# import torch
# from PIL import Image
# import torch.nn.functional as F
# import argparse
# import os



"""# 5. Image as Reference"""

!git clone https://github.com/facebookresearch/detectron2.git

!python -m pip install -e detectron2

!git clone https://github.com/aim-uofa/Matcher.git

!pwd
!ls

# Commented out IPython magic to ensure Python compatibility.
# %cd Matcher

!python3.9 -m pip install future==0.18.2 gradio==3.32.0 gradio-client==0.2.5 matplotlib==3.3.4 torch==1.13.1 torchvision==0.14.1

!python3.9 -m pip install torchmetrics==0.11.0 torchshow==0.5.0 timm==0.6.12 POT==0.9.0 omegaconf iopath numpy==1.22.0 tqdm==4.64.1

!python3.9 -m pip install gymnasium==1.0.0

!python3.9 -m pip install opencv-python==4.6.0.66

!python3.9 -m pip install scikit-learn==1.1.3

!python3.9 -m pip install kagglehub

!python3.9 --version

# !pip install scipy==1.10.1

!python3.9 -m pip show numpy



!mkdir output_segmentations

# !mv /kaggle/input/cv-a3-all/dinov2_vitl14_pretrain.pth /kaggle/input/cv-a3-all/sam_vit_h_4b8939.pth /kaggle/input/cv-a3-all/swint_only_sam_many2many.pth models





# def load_image(image_path):
#     img = Image.open(image_path).convert('RGB')
#     img = img.resize((518, 518))  ######## Resize to match Matcher's expected size
#     img = transforms.ToTensor()(img)
#     return img

# def create_binary_mask(mask):
#     return (mask > 0).astype(int) * 255

# def visualize_results(ref_img, ref_mask, query_img, pred_mask, save_path):
#     plt.figure(figsize=(15, 5))

#     plt.subplot(1, 4, 1)
#     plt.imshow(ref_img.permute(1, 2, 0).numpy())
#     plt.title('Reference Image')
#     plt.axis('off')

#     plt.subplot(1, 4, 2)
#     plt.imshow(ref_mask, cmap='gray')
#     plt.title('Reference Mask')
#     plt.axis('off')

#     plt.subplot(1, 4, 3)
#     plt.imshow(query_img.permute(1, 2, 0).numpy())
#     plt.title('Query Image')
#     plt.axis('off')

#     plt.subplot(1, 4, 4)
#     plt.imshow(pred_mask, cmap='gray')
#     plt.title('Predicted Mask')
#     plt.axis('off')

#     plt.savefig(save_path)
#     plt.close()

!pwd

# Commented out IPython magic to ensure Python compatibility.
# %%writefile actual.py
# import matplotlib
# matplotlib.use('Agg')
# 
# import numpy as np
# import matplotlib.pyplot as plt
# import torch
# from PIL import Image
# import torch.nn.functional as F
# import argparse
# import os
# 
# from torchvision import transforms
# import argparse
# import numpy as np
# 
# from matcher.Matcher import build_matcher_oss
# from segment_anything import sam_model_registry
# from dinov2.models import vision_transformer as vits
# import dinov2.utils.utils as dinov2_utils
# 
# device = "cuda" if torch.cuda.is_available() else "cpu"
# 
# import kagglehub
# kagglehub.login({
#     "username": "varinkala",
#     "key": "fba0c1d00c2aeea2d68a62e6237aea93"
# })
# 
# varinkala_cv_a3_all_path = kagglehub.dataset_download('varinkala/cv-a3-all')
# 
# print('Data source import complete.')
# 
# 
# def load_image(image_path):
#     img = Image.open(image_path).convert('RGB')
#     img = img.resize((518, 518))
#     img = transforms.ToTensor()(img)
#     return img
# 
# def create_binary_mask(mask):
#     return (mask > 0).astype(int) * 255
# 
# def visualize_results(ref_img, ref_mask, query_img, pred_mask, save_path):
#     plt.figure(figsize=(15, 5))
# 
#     plt.subplot(1, 4, 1)
#     plt.imshow(ref_img.permute(1, 2, 0).numpy())
#     plt.title('Reference Image')
#     plt.axis('off')
# 
#     plt.subplot(1, 4, 2)
#     plt.imshow(ref_mask, cmap='gray')
#     plt.title('Reference Mask')
#     plt.axis('off')
# 
#     plt.subplot(1, 4, 3)
#     plt.imshow(query_img.permute(1, 2, 0).numpy())
#     plt.title('Query Image')
#     plt.axis('off')
# 
#     plt.subplot(1, 4, 4)
#     plt.imshow(pred_mask, cmap='gray')
#     plt.title('Predicted Mask')
#     plt.axis('off')
# 
#     plt.savefig(save_path)
#     plt.close()
# 
# 
# images_dir= varinkala_cv_a3_all_path + '/Images-20250418T060633Z-001/Images'
# output_dir='output_segmentations'
# dinov2_weights= varinkala_cv_a3_all_path + '/dinov2_vitl14_pretrain.pth'
# sam_weights= varinkala_cv_a3_all_path + '/sam_vit_h_4b8939.pth'
# 
# args = argparse.Namespace(
#     images_dir=images_dir,
#     output_dir=output_dir,
#     dinov2_weights=dinov2_weights,
#     sam_weights=sam_weights,
# 
#     dinov2_size='vit_large',
#     sam_size='vit_h',
#     num_centers=8,
#     use_box=False,
#     use_points_or_centers=False,
#     sample_range="(4,6)",
#     max_sample_iterations=30,
#     alpha=1.0,
#     beta=0.0,
#     exp=0.0,
#     emd_filter=0.0,
#     purity_filter=0.0,
#     coverage_filter=0.0,
#     use_score_filter=False,
#     deep_score_norm_filter=0.1,
#     deep_score_filter=0.33,
#     topk_scores_threshold=0.7,
#     num_merging_mask=10,
# 
#     points_per_side=64,
#     pred_iou_thresh=0.88,
#     stability_score_thresh=0.95,
#     sel_stability_score_thresh=0.0,
#     iou_filter=0.0,
#     box_nms_thresh=1.0,
#     output_layer=3,
#     dense_multimask_output=0,
#     use_dense_mask=0,
#     multimask_output=0
# )
# 
# args.sample_range = eval(args.sample_range)
# 
# args.device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
# 
# matcher = build_matcher_oss(args)
# 
# for subfolder in os.listdir(images_dir):
#     subfolder_path = os.path.join(images_dir, subfolder)
#     if not os.path.isdir(subfolder_path):
#         continue
# 
#     image_files = [f for f in os.listdir(subfolder_path) if f.endswith(('.jpg', '.png'))]
#     if len(image_files) != 2:
#         print(f"Skipping {subfolder} - expected 2 images, found {len(image_files)}")
#         continue
# 
#     for i in range(2):
#         ref_idx = i
#         query_idx = 1 - i
# 
#         ref_img = load_image(os.path.join(subfolder_path, image_files[ref_idx]))
#         query_img = load_image(os.path.join(subfolder_path, image_files[query_idx]))
# 
#         ref_mask = torch.ones((1, 518, 518))
# 
#         batch = {
#             'query_img': query_img.unsqueeze(0),
#             'query_mask': torch.zeros((1, 1, 518, 518)),
#             'support_imgs': ref_img.unsqueeze(0).unsqueeze(0),
#             'support_masks': ref_mask.unsqueeze(0),
#             'class_id': torch.tensor([0])
#         }
# 
#         batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}
# 
#         matcher.set_reference(batch['support_imgs'], batch['support_masks'])
#         matcher.set_target(batch['query_img'])
# 
#         with torch.no_grad():
#             pred_mask = matcher.predict()
# 
#         matcher.clear()
# 
#         pred_mask_np = pred_mask.squeeze().cpu().numpy()
#         pred_mask_np = create_binary_mask(pred_mask_np)
# 
#         save_path = os.path.join(output_dir, f"{subfolder}_ref{ref_idx}_query{query_idx}.png")
#         try:
#             visualize_results(
#                 ref_img,
#                 ref_mask.squeeze().cpu().numpy(),
#                 query_img,
#                 pred_mask_np,
#                 save_path
#             )
#             print(f"Saved visualization to {save_path}")
#         except Exception as e:
#             print(f"Error saving visualization to {save_path}: {str(e)}")
# 
#         print(f"Processed {subfolder} - Reference: {image_files[ref_idx]}, Query: {image_files[query_idx]}")

!python3.9 actual.py

# from google.colab import drive
# drive.mount('/content/drive')

# import os
# import shutil

# # Define source and destination paths
# source_folder = 'output_segmentations/'  # Path to the output_segmentations folder
# destination_folder = '/content/drive/MyDrive/CV_A3_Q5_segmentations/'  # Path to the folder in your Drive

# # Create the destination folder if it doesn't exist
# os.makedirs(destination_folder, exist_ok=True)

# # Iterate through all files in the source folder
# for filename in os.listdir(source_folder):
#   # Construct the full file paths
#   source_path = os.path.join(source_folder, filename)
#   destination_path = os.path.join(destination_folder, filename)

#   # Copy the file to the destination folder
#   shutil.copy(source_path, destination_path)

# print(f"Images uploaded to {destination_folder}")

# kagglehub details:
# Username: varinkala
# token: fba0c1d00c2aeea2d68a62e6237aea93

# %tb